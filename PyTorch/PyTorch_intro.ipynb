{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "PyTorch_intro.ipynb",
      "version": "0.3.2",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "metadata": {
        "id": "_bJDWSIXLPsr",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "!pip3 install torchvision"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "DVL_NCs3LrK1",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "# Understanding gradient descent\n",
        "\n",
        "x_data = [1.0, 2.0, 3.0]\n",
        "y_data = [2.0, 4.0, 6.0]\n",
        "\n",
        "w = 1.0\n",
        "\n",
        "def forward(x):\n",
        "    return x*w\n",
        "\n",
        "def loss(x, y):\n",
        "    y_pred = forward(x)\n",
        "    return (y_pred - y)*(y_pred - y)\n",
        "\n",
        "def gradient(x, y):\n",
        "    return 2*x*(x*w - y)\n",
        "\n",
        "print('My prediction before training', 4, forward(4))\n",
        "\n",
        "for epoch in range(10):\n",
        "    for x_val, y_val in zip(x_data, y_data):\n",
        "        grad = gradient(x_val, y_val)\n",
        "        learning_rate = 0.01\n",
        "        w = w - learning_rate * grad\n",
        "        print('\\tgrad:', x_val, y_val, round(grad, 2))\n",
        "        l = loss(x_val, y_val)\n",
        "    print('Progress:', epoch, \"w=\", round(w,2), 'loss', round(l, 2))\n",
        "\n",
        "print('My new prediction after training', forward(4))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "i73sM0u3R4bh",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "# Now lets apply PyTorch\n",
        "\n",
        "import torch\n",
        "from torch.autograd import Variable\n",
        "\n",
        "x_data = [1.0, 2.0, 3.0]\n",
        "y_data = [2.0, 4.0, 6.0]\n",
        "\n",
        "w = Variable(torch.Tensor([1.0]), requires_grad = True)\n",
        "\n",
        "# As we can use functions from previous cell, i`m not gonna to rewrite it\n",
        "\n",
        "print('My prediction before training {} : {} '.format(4, forward(4).data[0]))\n",
        "\n",
        "for epoch in range(10):\n",
        "    for x_val, y_val in zip(x_data, y_data):\n",
        "        l = loss(x_val, y_val)\n",
        "        l.backward()\n",
        "        print('\\tgrad:', x_val, y_val, w.grad.data[0])\n",
        "        learning_rate = 0.01\n",
        "        w.data = w.data - learning_rate * w.grad.data\n",
        "        \n",
        "        w.grad.data.zero_()\n",
        "        \n",
        "    print('Progress: {} loss: {}'.format(epoch, l.data[0]))\n",
        "    \n",
        "print('My new prediction after training', forward(4).data[0])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "MpwyBIOUWmmL",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "# Linear regression in PyTorch\n",
        "\n",
        "import torch\n",
        "from torch.autograd import Variable\n",
        "\n",
        "x_data = Variable(torch.Tensor([[1.0], [2.0], [3.0]]))\n",
        "y_data = Variable(torch.Tensor([[2.0], [4.0], [6.0]]))\n",
        "\n",
        "class Model(torch.nn.Module):\n",
        "    def __init__(self):\n",
        "        super(Model, self).__init__()\n",
        "        \n",
        "        self.linear = torch.nn.Linear(1, 1)\n",
        "        \n",
        "    def forward(self, x):\n",
        "        y_pred = self.linear(x)\n",
        "        return y_pred\n",
        "    \n",
        "model = Model()\n",
        "\n",
        "criterion = torch.nn.MSELoss(size_average = False)\n",
        "optimizer = torch.optim.SGD(model.parameters(), lr=0.01)\n",
        "\n",
        "for epoch in range(100):\n",
        "    \n",
        "    y_pred = model(x_data)\n",
        "    \n",
        "    loss = criterion(y_pred, y_data)\n",
        "    print(epoch, loss.data[0])\n",
        "    \n",
        "    optimizer.zero_grad()\n",
        "    loss.backward()\n",
        "    optimizer.step()\n",
        "    \n",
        "output = Variable(torch.Tensor([[4.0]]))\n",
        "y_pred = model(output)\n",
        "print(\"prediction after the training\", 4, model(output).data[0][0])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "EXhshKvLLDui",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 153
        },
        "outputId": "c2920393-c791-440c-a672-2c251586c843"
      },
      "cell_type": "code",
      "source": [
        "# Deep Neural Network example\n",
        "\n",
        "# Downloaded this dataset from kaggle. Just type diabetes.csv to find that one\n",
        "d = 'diabetes.csv'\n",
        "\n",
        "import torch\n",
        "from torch.autograd import Variable\n",
        "import numpy as np\n",
        "import torch.nn.functional as F\n",
        "\n",
        "xy = np.loadtxt(d, delimiter=',', dtype=np.float32, skiprows=1)"
      ],
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[  6.   , 148.   ,  72.   , ...,   0.627,  50.   ,   1.   ],\n",
              "       [  1.   ,  85.   ,  66.   , ...,   0.351,  31.   ,   0.   ],\n",
              "       [  8.   , 183.   ,  64.   , ...,   0.672,  32.   ,   1.   ],\n",
              "       ...,\n",
              "       [  5.   , 121.   ,  72.   , ...,   0.245,  30.   ,   0.   ],\n",
              "       [  1.   , 126.   ,  60.   , ...,   0.349,  47.   ,   1.   ],\n",
              "       [  1.   ,  93.   ,  70.   , ...,   0.315,  23.   ,   0.   ]],\n",
              "      dtype=float32)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 9
        }
      ]
    },
    {
      "metadata": {
        "id": "y0pTopUSM12O",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "x_data = Variable(torch.from_numpy(xy[:, 0:-1]))\n",
        "y_data = Variable(torch.from_numpy(xy[:, [-1]]))\n",
        "\n",
        "class Model(torch.nn.Module):\n",
        "    def __init__(self):\n",
        "        super(Model, self).__init__()\n",
        "        \n",
        "        self.l1 = torch.nn.Linear(8, 6)\n",
        "        self.l2 = torch.nn.Linear(6, 4)\n",
        "        self.l3 = torch.nn.Linear(4, 1)\n",
        "        \n",
        "        self.sigmoid = torch.nn.Sigmoid()\n",
        "        \n",
        "    def forward(self, x):\n",
        "        \n",
        "        out1 = F.relu(self.l1(x))\n",
        "        out2 = F.relu(self.l2(out1))\n",
        "        y_pred = self.sigmoid(self.l3(out2))\n",
        "        \n",
        "        return y_pred\n",
        "    \n",
        "model = Model()\n",
        "\n",
        "criterion = torch.nn.BCELoss(size_average = True)\n",
        "optimizer = torch.optim.SGD(model.parameters(), lr=0.1)\n",
        "\n",
        "for epoch in range(100):\n",
        "    y_pred = model(x_data)\n",
        "    \n",
        "    loss = criterion(y_pred, y_data)\n",
        "    \n",
        "    print('Epoch: {}, loss: {}'.format(epoch, loss.data[0]))\n",
        "    \n",
        "    optimizer.zero_grad()\n",
        "    loss.backward()\n",
        "    optimizer.step()\n",
        "    \n",
        "    "
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "7ImMTpeySMe0",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1819
        },
        "outputId": "4133f265-fd8a-42e3-dacb-c713fe9cab6c"
      },
      "cell_type": "code",
      "source": [
        "# CNN in Pytorch\n",
        "# Ahh, again MNIST dataset\n",
        "\n",
        "import argparse\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "import torch.optim as optim\n",
        "from torchvision import datasets, transforms\n",
        "from torch.autograd import Variable\n",
        "\n",
        "batch_size = 128\n",
        "\n",
        "train_dataset = datasets.MNIST(root='/data/', train=True, transform=transforms.ToTensor(), download = True)\n",
        "test_dataset = datasets.MNIST(root='/data/', train=False, transform=transforms.ToTensor())\n",
        "\n",
        "train_loader = torch.utils.data.DataLoader(dataset=train_dataset, batch_size=batch_size, shuffle=True)\n",
        "test_loader = torch.utils.data.DataLoader(dataset=test_dataset, batch_size=batch_size, shuffle=False)\n",
        "\n",
        "class CNN(nn.Module):\n",
        "    def __init__(self):\n",
        "        super(CNN, self).__init__()\n",
        "        \n",
        "        self.conv1 = nn.Conv2d(1, 10, kernel_size=5)\n",
        "        self.conv2 = nn.Conv2d(10, 20, kernel_size=5)\n",
        "        self.mp = nn.MaxPool2d(2)\n",
        "        \n",
        "        self.fc = nn.Linear(320, 10)\n",
        "        \n",
        "    def forward(self, x):\n",
        "        initial_size = x.size(0)\n",
        "        \n",
        "        x = F.relu(self.mp(self.conv1(x)))\n",
        "        x = F.relu(self.mp(self.conv2(x)))\n",
        "        x = x.view(initial_size, -1)\n",
        "        x = self.fc(x)\n",
        "        \n",
        "        return F.log_softmax(x)\n",
        "    \n",
        "model = CNN()\n",
        "optimizer = optim.SGD(model.parameters(), lr=0.01, momentum=0.5)\n",
        "\n",
        "def train(epoch):\n",
        "    model.train()\n",
        "    for batch_idx, (data, target) in enumerate(train_loader):\n",
        "        data, target = Variable(data), Variable(target)\n",
        "        optimizer.zero_grad()\n",
        "        output = model(data)\n",
        "        loss = F.nll_loss(output, target)\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "        if batch_idx % 10 == 0:\n",
        "            print('Train Epoch: {} [{}/{}] ({:.0f}%]\\tLoss: {:.6f}'.format(epoch, batch_idx*len(data), len(train_loader.dataset), \n",
        "                                                                          100. * batch_idx / len(train_loader), loss.data[0]))\n",
        "\n",
        "def test():\n",
        "    model.eval()\n",
        "    test_loss = 0\n",
        "    correct = 0\n",
        "    for data, target in test_loader:\n",
        "        data, target = Variable(data, volatile=True), Variable(target)\n",
        "        output = model(data)\n",
        "        test_loss += F.nll_loss(output, target, size_average=False).data[0]\n",
        "        pred = output.data.max(1, keepdim=True)[1]\n",
        "        correct += pred.eq(target.data.view_as(pred)).cpu().sum()\n",
        "        \n",
        "    test_loss /= len(test_loader.dataset)\n",
        "    print('\\nTest set: Average loss: {:.4f}, Accuracy:{}/{} ({:0f}%\\n)'.format(test_loss, correct, len(test_loader.dataset), \n",
        "                                                                              100. * correct / len(test_loader.dataset)))\n",
        "    \n",
        "for epoch in range(1, 3):\n",
        "    train(epoch)\n",
        "    test()"
      ],
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:36: UserWarning: Implicit dimension choice for log_softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:52: UserWarning: invalid index of a 0-dim tensor. This will be an error in PyTorch 0.5. Use tensor.item() to convert a 0-dim tensor to a Python number\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Train Epoch: 1 [0/60000] (0%]\tLoss: 2.305419\n",
            "Train Epoch: 1 [1280/60000] (2%]\tLoss: 2.305606\n",
            "Train Epoch: 1 [2560/60000] (4%]\tLoss: 2.295037\n",
            "Train Epoch: 1 [3840/60000] (6%]\tLoss: 2.288960\n",
            "Train Epoch: 1 [5120/60000] (9%]\tLoss: 2.266279\n",
            "Train Epoch: 1 [6400/60000] (11%]\tLoss: 2.264006\n",
            "Train Epoch: 1 [7680/60000] (13%]\tLoss: 2.245130\n",
            "Train Epoch: 1 [8960/60000] (15%]\tLoss: 2.227899\n",
            "Train Epoch: 1 [10240/60000] (17%]\tLoss: 2.200622\n",
            "Train Epoch: 1 [11520/60000] (19%]\tLoss: 2.168125\n",
            "Train Epoch: 1 [12800/60000] (21%]\tLoss: 2.106326\n",
            "Train Epoch: 1 [14080/60000] (23%]\tLoss: 2.020199\n",
            "Train Epoch: 1 [15360/60000] (26%]\tLoss: 1.881897\n",
            "Train Epoch: 1 [16640/60000] (28%]\tLoss: 1.709609\n",
            "Train Epoch: 1 [17920/60000] (30%]\tLoss: 1.489804\n",
            "Train Epoch: 1 [19200/60000] (32%]\tLoss: 1.229862\n",
            "Train Epoch: 1 [20480/60000] (34%]\tLoss: 1.033832\n",
            "Train Epoch: 1 [21760/60000] (36%]\tLoss: 0.772351\n",
            "Train Epoch: 1 [23040/60000] (38%]\tLoss: 0.708301\n",
            "Train Epoch: 1 [24320/60000] (41%]\tLoss: 0.682998\n",
            "Train Epoch: 1 [25600/60000] (43%]\tLoss: 0.625637\n",
            "Train Epoch: 1 [26880/60000] (45%]\tLoss: 0.445162\n",
            "Train Epoch: 1 [28160/60000] (47%]\tLoss: 0.616257\n",
            "Train Epoch: 1 [29440/60000] (49%]\tLoss: 0.476997\n",
            "Train Epoch: 1 [30720/60000] (51%]\tLoss: 0.395393\n",
            "Train Epoch: 1 [32000/60000] (53%]\tLoss: 0.440742\n",
            "Train Epoch: 1 [33280/60000] (55%]\tLoss: 0.531388\n",
            "Train Epoch: 1 [34560/60000] (58%]\tLoss: 0.446156\n",
            "Train Epoch: 1 [35840/60000] (60%]\tLoss: 0.249610\n",
            "Train Epoch: 1 [37120/60000] (62%]\tLoss: 0.428157\n",
            "Train Epoch: 1 [38400/60000] (64%]\tLoss: 0.428973\n",
            "Train Epoch: 1 [39680/60000] (66%]\tLoss: 0.366100\n",
            "Train Epoch: 1 [40960/60000] (68%]\tLoss: 0.376545\n",
            "Train Epoch: 1 [42240/60000] (70%]\tLoss: 0.287346\n",
            "Train Epoch: 1 [43520/60000] (72%]\tLoss: 0.376616\n",
            "Train Epoch: 1 [44800/60000] (75%]\tLoss: 0.305645\n",
            "Train Epoch: 1 [46080/60000] (77%]\tLoss: 0.303387\n",
            "Train Epoch: 1 [47360/60000] (79%]\tLoss: 0.426021\n",
            "Train Epoch: 1 [48640/60000] (81%]\tLoss: 0.316272\n",
            "Train Epoch: 1 [49920/60000] (83%]\tLoss: 0.441188\n",
            "Train Epoch: 1 [51200/60000] (85%]\tLoss: 0.324742\n",
            "Train Epoch: 1 [52480/60000] (87%]\tLoss: 0.361059\n",
            "Train Epoch: 1 [53760/60000] (90%]\tLoss: 0.301934\n",
            "Train Epoch: 1 [55040/60000] (92%]\tLoss: 0.243734\n",
            "Train Epoch: 1 [56320/60000] (94%]\tLoss: 0.295525\n",
            "Train Epoch: 1 [57600/60000] (96%]\tLoss: 0.231569\n",
            "Train Epoch: 1 [58880/60000] (98%]\tLoss: 0.318551\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:59: UserWarning: volatile was removed and now has no effect. Use `with torch.no_grad():` instead.\n",
            "/usr/local/lib/python3.6/dist-packages/torch/nn/functional.py:52: UserWarning: size_average and reduce args will be deprecated, please use reduction='sum' instead.\n",
            "  warnings.warn(warning.format(ret))\n",
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:61: UserWarning: invalid index of a 0-dim tensor. This will be an error in PyTorch 0.5. Use tensor.item() to convert a 0-dim tensor to a Python number\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "\n",
            "Test set: Average loss: 0.2653, Accuracy:9238/10000 (92.000000%\n",
            ")\n",
            "Train Epoch: 2 [0/60000] (0%]\tLoss: 0.456573\n",
            "Train Epoch: 2 [1280/60000] (2%]\tLoss: 0.209446\n",
            "Train Epoch: 2 [2560/60000] (4%]\tLoss: 0.232900\n",
            "Train Epoch: 2 [3840/60000] (6%]\tLoss: 0.205544\n",
            "Train Epoch: 2 [5120/60000] (9%]\tLoss: 0.336632\n",
            "Train Epoch: 2 [6400/60000] (11%]\tLoss: 0.278762\n",
            "Train Epoch: 2 [7680/60000] (13%]\tLoss: 0.223898\n",
            "Train Epoch: 2 [8960/60000] (15%]\tLoss: 0.257477\n",
            "Train Epoch: 2 [10240/60000] (17%]\tLoss: 0.233646\n",
            "Train Epoch: 2 [11520/60000] (19%]\tLoss: 0.341477\n",
            "Train Epoch: 2 [12800/60000] (21%]\tLoss: 0.195001\n",
            "Train Epoch: 2 [14080/60000] (23%]\tLoss: 0.369264\n",
            "Train Epoch: 2 [15360/60000] (26%]\tLoss: 0.274097\n",
            "Train Epoch: 2 [16640/60000] (28%]\tLoss: 0.308343\n",
            "Train Epoch: 2 [17920/60000] (30%]\tLoss: 0.276862\n",
            "Train Epoch: 2 [19200/60000] (32%]\tLoss: 0.384606\n",
            "Train Epoch: 2 [20480/60000] (34%]\tLoss: 0.227146\n",
            "Train Epoch: 2 [21760/60000] (36%]\tLoss: 0.179087\n",
            "Train Epoch: 2 [23040/60000] (38%]\tLoss: 0.188329\n",
            "Train Epoch: 2 [24320/60000] (41%]\tLoss: 0.220363\n",
            "Train Epoch: 2 [25600/60000] (43%]\tLoss: 0.251438\n",
            "Train Epoch: 2 [26880/60000] (45%]\tLoss: 0.163026\n",
            "Train Epoch: 2 [28160/60000] (47%]\tLoss: 0.192992\n",
            "Train Epoch: 2 [29440/60000] (49%]\tLoss: 0.297321\n",
            "Train Epoch: 2 [30720/60000] (51%]\tLoss: 0.396414\n",
            "Train Epoch: 2 [32000/60000] (53%]\tLoss: 0.184012\n",
            "Train Epoch: 2 [33280/60000] (55%]\tLoss: 0.310632\n",
            "Train Epoch: 2 [34560/60000] (58%]\tLoss: 0.159224\n",
            "Train Epoch: 2 [35840/60000] (60%]\tLoss: 0.238991\n",
            "Train Epoch: 2 [37120/60000] (62%]\tLoss: 0.163882\n",
            "Train Epoch: 2 [38400/60000] (64%]\tLoss: 0.126198\n",
            "Train Epoch: 2 [39680/60000] (66%]\tLoss: 0.260588\n",
            "Train Epoch: 2 [40960/60000] (68%]\tLoss: 0.102186\n",
            "Train Epoch: 2 [42240/60000] (70%]\tLoss: 0.190010\n",
            "Train Epoch: 2 [43520/60000] (72%]\tLoss: 0.144570\n",
            "Train Epoch: 2 [44800/60000] (75%]\tLoss: 0.197395\n",
            "Train Epoch: 2 [46080/60000] (77%]\tLoss: 0.214989\n",
            "Train Epoch: 2 [47360/60000] (79%]\tLoss: 0.155362\n",
            "Train Epoch: 2 [48640/60000] (81%]\tLoss: 0.289595\n",
            "Train Epoch: 2 [49920/60000] (83%]\tLoss: 0.206656\n",
            "Train Epoch: 2 [51200/60000] (85%]\tLoss: 0.291686\n",
            "Train Epoch: 2 [52480/60000] (87%]\tLoss: 0.194008\n",
            "Train Epoch: 2 [53760/60000] (90%]\tLoss: 0.104219\n",
            "Train Epoch: 2 [55040/60000] (92%]\tLoss: 0.241122\n",
            "Train Epoch: 2 [56320/60000] (94%]\tLoss: 0.112120\n",
            "Train Epoch: 2 [57600/60000] (96%]\tLoss: 0.292551\n",
            "Train Epoch: 2 [58880/60000] (98%]\tLoss: 0.163947\n",
            "\n",
            "Test set: Average loss: 0.1741, Accuracy:9511/10000 (95.000000%\n",
            ")\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "ZVfWRivvX208",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "\n"
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}